{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5RJKDHiQjz9bSf+MX2o+T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2Anshika6/Skin-Cancer-Detection/blob/main/final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKDI7MT7vUoe"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "from tensorflow.keras.applications import ResNet50, VGG16, InceptionV3, EfficientNetB0, DenseNet201\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_resnet\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input as preprocess_vgg\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input as preprocess_inception\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input as preprocess_efficientnet\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "from tensorflow.keras.applications.densenet import preprocess_input as preprocess_densenet\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam # - Works\n",
        "import random\n",
        "from glob import glob\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "Dfr6C7qqvWGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_dir = '/content/drive/MyDrive/Skin cancer ISIC The International Skin Imaging Collaboration/Train/'\n",
        "# test_dir = '/content/drive/MyDrive/Skin cancer ISIC The International Skin Imaging Collaboration/Test/'\n",
        "\n",
        "train_dir = '/content/drive/MyDrive/Colab Notebooks/Skin cancer ISIC The International Skin Imaging Collaboration/Train/'\n",
        "test_dir = '/content/drive/MyDrive/Colab Notebooks/Skin cancer ISIC The International Skin Imaging Collaboration/Test/'"
      ],
      "metadata": {
        "id": "d7ieBgKZvZRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_classes = os.listdir(train_dir)\n",
        "test_classes = os.listdir(test_dir)"
      ],
      "metadata": {
        "id": "LWUN3umZvecc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_images_by_class(directory):\n",
        "    class_counts = {}\n",
        "    for class_name in os.listdir(directory):\n",
        "        class_path = os.path.join(directory, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            class_counts[class_name] = len(os.listdir(class_path))\n",
        "    return class_counts"
      ],
      "metadata": {
        "id": "tA8oqDj-vf04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_counts = count_images_by_class(train_dir)\n",
        "\n",
        "print(train_counts)"
      ],
      "metadata": {
        "id": "kClSB1PbvfxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_counts = count_images_by_class(test_dir)\n",
        "\n",
        "print(test_counts)"
      ],
      "metadata": {
        "id": "uGZ2evvIvfvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_class_counts(class_counts, title):\n",
        "    plt.figure(figsize=(15, 4))\n",
        "    sns.barplot(x=list(class_counts.keys()), y=list(class_counts.values()), palette=\"viridis\")\n",
        "    plt.title(title)\n",
        "    plt.ylabel(\"Image Count\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "plot_class_counts(train_counts, \"Train Dataset Image Counts by Class\")\n",
        "plot_class_counts(test_counts, \"Test Dataset Image Counts by Class\")"
      ],
      "metadata": {
        "id": "PRi5tvSqvfsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_images_per_class(directory, n_images=4):\n",
        "    for class_name in os.listdir(directory):\n",
        "        class_path = os.path.join(directory, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            image_files = os.listdir(class_path)[:n_images]\n",
        "            plt.figure(figsize=(15, 2))\n",
        "            plt.suptitle(f\"Class: {class_name}\", fontsize=16)\n",
        "            for i, img_file in enumerate(image_files):\n",
        "                img_path = os.path.join(class_path, img_file)\n",
        "                img = Image.open(img_path)\n",
        "                plt.subplot(1, n_images, i + 1)\n",
        "                plt.imshow(img)\n",
        "                plt.axis('off')\n",
        "            plt.show()\n",
        "\n",
        "display_images_per_class(train_dir)"
      ],
      "metadata": {
        "id": "YvvfJepevfqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET_COUNT = 3000\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")"
      ],
      "metadata": {
        "id": "34kH46l9vfnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "Y_train = []\n",
        "\n",
        "\n",
        "def load_and_augment_images(directory, class_name, current_count, target_count):\n",
        "    image_files = os.listdir(directory)\n",
        "\n",
        "    # Load existing images\n",
        "    for img_file in image_files:\n",
        "        img_path = os.path.join(directory, img_file)\n",
        "        # img = Image.open(img_path).resize((150, 150))  # Resize all images to (150, 150)\n",
        "        img = Image.open(img_path).resize((100, 100))\n",
        "        img_array = np.array(img)\n",
        "        img_array = img_array.astype('float32') / 255.0\n",
        "        X_train.append(img_array)\n",
        "        Y_train.append(class_name)\n",
        "\n",
        "    # Apply augmentation if the class has fewer images than the target\n",
        "    while current_count < target_count:\n",
        "        # Randomly pick an image for augmentation\n",
        "        img_file = random.choice(image_files)\n",
        "        img_path = os.path.join(directory, img_file)\n",
        "        # img = Image.open(img_path).resize((150, 150))\n",
        "        img = Image.open(img_path).resize((100, 100))\n",
        "        img_array = np.array(img).astype('float32') / 255.0\n",
        "        img_array = np.expand_dims(img_array, 0)  # Add batch dimension for augmentation\n",
        "\n",
        "        # Generate one augmented image at a time\n",
        "        augmented_img = next(datagen.flow(img_array, batch_size=1))[0].astype('float32')\n",
        "        X_train.append(augmented_img)\n",
        "        Y_train.append(class_name)\n",
        "        current_count += 1\n",
        "\n",
        "# Load and augment images for each class in the training directory\n",
        "for class_name, count in train_counts.items():\n",
        "    class_dir = os.path.join(train_dir, class_name)\n",
        "    load_and_augment_images(class_dir, class_name, count, TARGET_COUNT)\n",
        "\n",
        "# Convert the lists into NumPy arrays\n",
        "# X_train = np.array(X_train)\n",
        "X_train = np.array(X_train, dtype=np.float16)\n",
        "Y_train = np.array(Y_train)\n"
      ],
      "metadata": {
        "id": "mVcNsftqvrFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(\"Train Directory Exists:\", os.path.exists(train_dir))\n",
        "print(\"Classes in Train Directory:\", os.listdir(train_dir) if os.path.exists(train_dir) else \"Directory not found\")\n"
      ],
      "metadata": {
        "id": "ei-f4StQvrBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Final shape of X_train: {X_train.shape}\")\n",
        "print(f\"Final shape of y_train: {Y_train.shape}\")"
      ],
      "metadata": {
        "id": "L44-S9Yxvq_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_Y(y):\n",
        "    if y == 'actinic keratosis':\n",
        "        return 0\n",
        "    elif y == 'basal cell carcinoma':\n",
        "        return 1\n",
        "    elif y == 'dermatofibroma':\n",
        "        return 2\n",
        "    elif y == 'melanoma':\n",
        "        return 3\n",
        "    elif y == 'nevus':\n",
        "        return 4\n",
        "    elif y == 'pigmented benign keratosis':\n",
        "        return 5\n",
        "    elif y == 'seborrheic keratosis':\n",
        "        return 6\n",
        "    elif y == 'squamous cell carcinoma':\n",
        "        return 7\n",
        "    elif y == 'vascular lesion':\n",
        "        return 8"
      ],
      "metadata": {
        "id": "HIMTlfRZvq7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the shapes of the resulting splits\n",
        "print(f\"Training set size: {x_train.shape}, Labels: {y_train.shape}\")\n",
        "print(f\"Validation set size: {x_valid.shape}, Labels: {y_valid.shape}\")"
      ],
      "metadata": {
        "id": "egT95r-Tvq3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "o1Jx7kOfvqjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.array([transform_Y(y) for y in y_train])\n",
        "y_valid = np.array([transform_Y(y) for y in y_valid])\n",
        "\n",
        "# Verify the transformation by printing the first few transformed labels\n",
        "print(\"Transformed y_train:\", y_train[:5])\n",
        "print(\"Transformed y_valid:\", y_valid[:5])"
      ],
      "metadata": {
        "id": "EpyLmvRuvflP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to hold the test data and labels\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "# Function to load test images and encode the class labels\n",
        "def load_test_images(directory, class_name):\n",
        "    try:\n",
        "        image_files = os.listdir(directory)  # List all image files in the directory\n",
        "\n",
        "        # Load and process images\n",
        "        for img_file in image_files:\n",
        "            img_path = os.path.join(directory, img_file)\n",
        "\n",
        "            # Open and resize the image\n",
        "            # img = Image.open(img_path).resize((150, 150))\n",
        "            img = Image.open(img_path).resize((100, 100))\n",
        "            img_array = np.array(img)\n",
        "            img_array = img_array.astype('float32') / 255.0  # Normalize pixel values\n",
        "            X_test.append(img_array)\n",
        "\n",
        "            # Encode the label using transform_Y function\n",
        "            encoded_label = transform_Y(class_name)\n",
        "            y_test.append(encoded_label)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {class_name} in {directory}: {e}\")\n",
        "\n",
        "# Transform function for encoding the class labels\n",
        "def transform_Y(y):\n",
        "    if y == 'actinic keratosis':\n",
        "        return 0\n",
        "    elif y == 'basal cell carcinoma':\n",
        "        return 1\n",
        "    elif y == 'dermatofibroma':\n",
        "        return 2\n",
        "    elif y == 'melanoma':\n",
        "        return 3\n",
        "    elif y == 'nevus':\n",
        "        return 4\n",
        "    elif y == 'pigmented benign keratosis':\n",
        "        return 5\n",
        "    elif y == 'seborrheic keratosis':\n",
        "        return 6\n",
        "    elif y == 'squamous cell carcinoma':\n",
        "        return 7\n",
        "    elif y == 'vascular lesion':\n",
        "        return 8\n",
        "    else:\n",
        "        return -1  # For unknown or new labels\n",
        "\n",
        "# Example list of test classes\n",
        "test_classes = ['actinic keratosis', 'basal cell carcinoma','dermatofibroma', 'melanoma', 'nevus', 'pigmented benign keratosis',\n",
        "              'seborrheic keratosis', 'squamous cell carcinoma', 'vascular lesion' ]\n",
        "\n",
        "\n",
        "# Load test images for each class in the test directory\n",
        "for class_name in test_classes:\n",
        "    class_dir = os.path.join(test_dir, class_name)\n",
        "    load_test_images(class_dir, class_name)\n",
        "\n",
        "# Convert the lists into NumPy arrays\n",
        "# x_test = np.array(X_test) changed\n",
        "X_test = np.array(X_test, dtype=np.float16)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "9OvyFXQFvfb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert y_train and y_valid to one-hot encoded format\n",
        "y_train_one_hot = to_categorical(y_train, num_classes=9)\n",
        "y_valid_one_hot = to_categorical(y_valid, num_classes=9)\n",
        "y_test_one_hot = to_categorical(y_test, num_classes=9)"
      ],
      "metadata": {
        "id": "rgT_P10_vfPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(np.unique(y_test))"
      ],
      "metadata": {
        "id": "VSc_vuDjv4nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, BatchNormalization, Dropout\n",
        "\n",
        "input_layer = Input(shape=(100, 100, 3))\n",
        "\n",
        "def create_model(base_model):\n",
        "    # Freeze all layers except the last 30 in the base model\n",
        "    for layer in base_model.layers[:-30]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Define the input layer\n",
        "    input_layer = Input(shape=(100, 100, 3))\n",
        "\n",
        "    # Use the base model as a feature extractor\n",
        "    x = base_model(input_layer, training=False)\n",
        "\n",
        "    # Add custom layers on top of the base model\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)  # Dropout added here\n",
        "\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Output layer for 9 classes\n",
        "    output_layer = Dense(9, activation='softmax')(x)\n",
        "\n",
        "    # Create the final model\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "7lVNefvAv4kK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import AdamW\n",
        "base_model = DenseNet201(weights='imagenet', include_top=False, input_tensor = input_layer)\n",
        "\n",
        "\n",
        "# Create the model using Inceptionv3 as the base feature extractor\n",
        "densenet_model = create_model(base_model)\n",
        "\n",
        "# Compile the model\n",
        "optimizer = AdamW(learning_rate=1e-4, weight_decay=1e-4)\n",
        "densenet_model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "densenet_model.summary()"
      ],
      "metadata": {
        "id": "Y-VzY6TQv4h2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# epochs = 15 change batch 128\n",
        "epochs = 7\n",
        "batch_size=64\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-4,verbose=1)\n",
        "# Now fit the model with the one-hot encoded labels\n",
        "densenet_history = densenet_model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(x_valid, y_valid),\n",
        "    callbacks=[EarlyStopping(monitor='val_loss', patience=5,restore_best_weights=True),lr_scheduler]\n",
        ")"
      ],
      "metadata": {
        "id": "zntVZhOqv4fO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_history(history):\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # Accuracy plot\n",
        "    ax1.plot(history.history['accuracy'])\n",
        "    ax1.plot(history.history['val_accuracy'])\n",
        "    ax1.set_title('Model Accuracy')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Accuracy')\n",
        "    ax1.legend(['Train', 'Validation'])\n",
        "\n",
        "    # Loss plot\n",
        "    ax2.plot(history.history['loss'])\n",
        "    ax2.plot(history.history['val_loss'])\n",
        "    ax2.set_title('Model Loss')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Loss')\n",
        "    ax2.legend(['Train', 'Validation'])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "DHZcJV4cwAYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training history\n",
        "plot_training_history(densenet_history)"
      ],
      "metadata": {
        "id": "Ae0niE3kwAKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nFinal Training Metrics:\")\n",
        "for metric, value in densenet_history.history.items():\n",
        "    print(f\"{metric}: {value[-1]:.4f}\")\n",
        "\n",
        "y_pred_probs = model.predict(X_test)  # Probabilities for each class\n",
        "y_pred_class = np.argmax(y_pred_probs, axis=1)  # Convert to class labels\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "n_classes = 9  # Since we have 9 classes\n",
        "pauc_values = []\n",
        "\n",
        "for i in range(n_classes):\n",
        "    y_true_bin = (y_test == i).astype(int)  # Convert to binary labels for class i\n",
        "    fpr, tpr, _ = roc_curve(y_true_bin, y_pred_probs[:, i])  # Compute ROC\n",
        "\n",
        "    # Compute partial AUC (e.g., up to FPR of 0.1)\n",
        "    max_fpr = 0.1\n",
        "    pauc = auc(fpr[fpr <= max_fpr], tpr[fpr <= max_fpr])  # pAUC calculation\n",
        "    pauc_values.append(pauc)\n",
        "\n",
        "# Print partial AUC for each class\n",
        "for i, value in enumerate(pauc_values):\n",
        "    print(f\"pAUC for class {i}: {value:.4f}\")\n",
        "\n",
        "# Compute mean pAUC across all classes\n",
        "mean_pauc = np.mean(pauc_values)\n",
        "print(f\"\\nMean pAUC across all classes: {mean_pauc:.4f}\")\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "cm = confusion_matrix(y_test, y_pred_class)\n",
        "class_labels = [\n",
        "    \"Actinic Keratosis\", \"Basal Cell Carcinoma\", \"Dermatofibroma\",\n",
        "    \"Melanoma\", \"Nevus\", \"Pigmented Benign Keratosis\",\n",
        "    \"Seborrheic Keratosis\", \"Squamous Cell Carcinoma\", \"Vascular Lesion\"\n",
        "]\n",
        "# Plot confusion matrix\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
        "disp.plot(cmap=\"Blues\", xticks_rotation=45, ax=ax)\n",
        "\n",
        "# Explicitly set tick labels\n",
        "ax.set_xticks(np.arange(len(class_labels)))  # Ensure correct positions\n",
        "ax.set_xticklabels(class_labels, rotation=45, ha=\"right\")  # Align labels properly\n",
        "ax.set_yticks(np.arange(len(class_labels)))\n",
        "ax.set_yticklabels(class_labels)\n",
        "\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sykLgdJvv4TQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "densenet_model.save(\"densenet201_1.h5\")\n",
        "densenet_model.save(\"densenet201_1.keras\")"
      ],
      "metadata": {
        "id": "O1FULWHywFdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "keJl8fwNwFGE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}